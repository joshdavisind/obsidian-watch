{
  "name": "Metis",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "metis",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [-1600, 300],
      "webhookId": "metis"
    },
    {
      "parameters": {
        "rule": {
          "interval": [{ "field": "cronExpression", "expression": "0 2 * * *" }]
        }
      },
      "id": "nightly-cron",
      "name": "Nightly Cron (2am)",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1,
      "position": [-1600, 500]
    },
    {
      "parameters": {
        "url": "http://100.111.39.118:27123/vault/Work/Meta/Configuration/Metis-Config.md",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {}
      },
      "id": "read-config-note",
      "name": "Read Config Note",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [-1400, 300],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "const baseUrl = 'http://100.111.39.118:27123';\nconst authHeader = 'Bearer 4931ee13bc3472b907f251ce39d7b4229a4f7fc360c0ab8f52213329671a7b12';\n\nfunction encodePathPreservingSlashes(p) {\n  return p.split('/').filter(Boolean).map(encodeURIComponent).join('/');\n}\n\nasync function listDirectory(dirPath) {\n  const encoded = encodePathPreservingSlashes(dirPath);\n  const url = `${baseUrl}/vault/${encoded ? `${encoded}/` : ''}`;\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url,\n    headers: { Authorization: authHeader },\n    json: true,\n  });\n  return response?.files ?? [];\n}\n\nasync function scanFolders(startDir, depth = 0, maxDepth = 4) {\n  const results = { people: [], clients: {}, partners: [], teams: [], folders: [] };\n  if (depth > maxDepth) return results;\n  \n  const items = await listDirectory.call(this, startDir);\n  for (const item of items) {\n    if (!item.endsWith('/')) continue;\n    const name = item.slice(0, -1);\n    const fullPath = startDir ? `${startDir}/${name}` : name;\n    results.folders.push(fullPath);\n    \n    // Identify known folder types\n    if (fullPath.includes('One on One Meetings/') && depth === 3) {\n      results.people.push(name);\n    }\n    if (fullPath.includes('Active Deals/Clients/') && depth === 4) {\n      const location = fullPath.split('/')[4] || 'Unknown';\n      if (!results.clients[location]) results.clients[location] = [];\n      results.clients[location].push(name);\n    }\n    if (fullPath.includes('Active Deals/Partners/') && depth === 3) {\n      results.partners.push(name);\n    }\n    if (fullPath.includes('Expedient Teams/') && depth === 3) {\n      results.teams.push(name);\n    }\n    \n    // Recurse into subdirectories\n    const subResults = await scanFolders.call(this, fullPath, depth + 1, maxDepth);\n    results.folders.push(...subResults.folders);\n    results.people.push(...subResults.people);\n    results.partners.push(...subResults.partners);\n    results.teams.push(...subResults.teams);\n    for (const [loc, clients] of Object.entries(subResults.clients)) {\n      if (!results.clients[loc]) results.clients[loc] = [];\n      results.clients[loc].push(...clients);\n    }\n  }\n  return results;\n}\n\nconst structure = await scanFolders.call(this, 'Work');\nreturn { json: { vault_structure: structure } };"
      },
      "id": "scan-vault-structure",
      "name": "Scan Vault Structure",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-1400, 500]
    },
    {
      "parameters": {
        "mode": "combine",
        "combinationMode": "mergeByPosition",
        "options": {}
      },
      "id": "merge-context-inputs",
      "name": "Merge Context Inputs",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [-1200, 400]
    },
    {
      "parameters": {
        "jsCode": "// Get config content and vault structure\nconst items = $input.all();\nlet configContent = '';\nlet vaultStructure = { people: [], clients: {}, partners: [], teams: [], folders: [] };\n\nfor (const item of items) {\n  if (item.json.vault_structure) {\n    vaultStructure = item.json.vault_structure;\n  }\n  // Config note content comes as string or object with content\n  if (typeof item.json === 'string') {\n    configContent = item.json;\n  } else if (item.json.content) {\n    configContent = item.json.content;\n  } else if (!item.json.vault_structure && !item.json.error) {\n    // Might be raw markdown\n    configContent = JSON.stringify(item.json);\n  }\n}\n\n// Parse config note sections\nlet attendees = '';\nlet clients = '';\nlet partners = '';\nlet routingRules = '';\n\nif (configContent) {\n  // Extract Attendee Context section\n  const attendeeMatch = configContent.match(/## Attendee Context[\\s\\S]*?(?=\\n## |$)/i);\n  if (attendeeMatch) attendees = attendeeMatch[0].trim();\n  \n  // Extract Clients section\n  const clientMatch = configContent.match(/## Known Clients by Location[\\s\\S]*?(?=\\n## |$)/i);\n  if (clientMatch) clients = clientMatch[0].trim();\n  \n  // Extract Partners section\n  const partnerMatch = configContent.match(/## Known Partners[\\s\\S]*?(?=\\n## |$)/i);\n  if (partnerMatch) partners = partnerMatch[0].trim();\n  \n  // Extract Routing Rules section\n  const routingMatch = configContent.match(/## Folder Routing Rules[\\s\\S]*?(?=\\n## |$)/i);\n  if (routingMatch) routingRules = routingMatch[0].trim();\n}\n\n// Build context object\nconst context = {\n  attendees,\n  clients,\n  partners,\n  routing_rules: routingRules,\n  vault_structure: vaultStructure,\n  discovered_people: vaultStructure.people || [],\n  discovered_clients: vaultStructure.clients || {},\n  discovered_partners: vaultStructure.partners || [],\n  discovered_teams: vaultStructure.teams || []\n};\n\nreturn { json: { context } };"
      },
      "id": "store-context",
      "name": "Store Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-1000, 400]
    },
    {
      "parameters": {
        "jsCode": "// Get context from Store Context node\nconst context = $json.context || {};\n\nconst baseUrl = 'http://100.111.39.118:27123';\nconst authHeader = 'Bearer 4931ee13bc3472b907f251ce39d7b4229a4f7fc360c0ab8f52213329671a7b12';\n\nfunction encodePathPreservingSlashes(p) {\n  return p.split('/').filter(Boolean).map(encodeURIComponent).join('/');\n}\n\nasync function listDirectory(dirPath) {\n  const encoded = encodePathPreservingSlashes(dirPath);\n  const url = `${baseUrl}/vault/${encoded ? `${encoded}/` : ''}`;\n  const response = await this.helpers.httpRequest({\n    method: 'GET',\n    url,\n    headers: { Authorization: authHeader },\n    json: true,\n  });\n  return response?.files ?? [];\n}\n\nasync function findMarkdownFiles(startDir) {\n  const results = [];\n  const stack = [startDir];\n  while (stack.length) {\n    const dir = stack.pop();\n    const items = await listDirectory.call(this, dir);\n    for (const item of items) {\n      const isDirectory = item.endsWith('/');\n      const name = isDirectory ? item.slice(0, -1) : item;\n      const vaultPath = dir ? `${dir}/${name}` : name;\n      if (isDirectory) {\n        stack.push(vaultPath);\n        continue;\n      }\n      if (!name.endsWith('.md')) continue;\n      if (name === 'Dashboard.md') continue;\n      if (name.startsWith('Metis-Log-')) continue;\n      if (name.startsWith('Janitor-Log-')) continue;\n      if (name === 'Metis-Config.md') continue;\n      results.push(vaultPath);\n    }\n  }\n  return results;\n}\n\nconst files = await findMarkdownFiles.call(this, 'Work');\nconst limitedFiles = files.slice(0, 10);\n\nif (limitedFiles.length === 0) {\n  return [{ json: { vaultPath: '', skip: true, context } }];\n}\n\nreturn limitedFiles.map(vaultPath => ({ json: { vaultPath, skip: false, context } }));"
      },
      "id": "find-all-md-files",
      "name": "Find All MD Files",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-800, 400]
    },
    {
      "parameters": {
        "url": "=http://100.111.39.118:27123/vault/{{ $json.vaultPath || '' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {}
      },
      "id": "read-file-content",
      "name": "Read File Content",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [-600, 400],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "try {\n  const vaultRoot = '/Users/joshdavis/Library/Mobile Documents/iCloud~md~obsidian/Documents/dvsobs1';\n  const inputData = $('Find All MD Files').item.json;\n  const vaultPath = inputData.vaultPath || '';\n  const context = inputData.context || {};\n  const filepath = vaultPath ? `${vaultRoot}/${vaultPath}` : '';\n  const relativePath = vaultPath || '';\n  \n  let content = '';\n  if (typeof $json === 'string') {\n    content = $json;\n  } else if ($json && typeof $json === 'object') {\n    if ($json.content) content = $json.content;\n    else if ($json.data) content = $json.data;\n    else if ($json.body) content = $json.body;\n    else if ($json.text) content = $json.text;\n  }\n  \n  // Fix: If content itself looks like JSON-wrapped at start, unwrap it\n  if (content && content.trim().startsWith('{\"content\":')) {\n    try {\n      const parsed = JSON.parse(content.trim());\n      if (parsed.content) content = parsed.content;\n    } catch (e) {}\n  }\n  \n  if ($json && $json.error) {\n    return { json: { filepath, filename: vaultPath.split('/').pop() || '', current_folder: vaultPath.substring(0, vaultPath.lastIndexOf('/')) || '', relative_path: relativePath, frontmatter: {}, content: '', has_frontmatter: false, error: $json.error.message || 'API error', context } };\n  }\n  \n  const fmMatch = content.match(/^---\\n([\\s\\S]*?)\\n---/);\n  let frontmatter = {};\n  let bodyContent = content;\n  \n  if (fmMatch) {\n    fmMatch[1].split('\\n').forEach(line => {\n      const trimmed = line.trim();\n      if (trimmed && trimmed.includes(':')) {\n        const [key, ...valueParts] = trimmed.split(':');\n        if (key && valueParts.length) {\n          frontmatter[key.trim()] = valueParts.join(':').trim().replace(/^[\"']|[\"']$/g, '');\n        }\n      }\n    });\n    // Extract body after frontmatter\n    bodyContent = content.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n  }\n  \n  // Fix: If body content is JSON-wrapped, unwrap it recursively\n  let unwrapAttempts = 0;\n  while (bodyContent.trim().startsWith('{\"content\":') && unwrapAttempts < 5) {\n    try {\n      const parsed = JSON.parse(bodyContent.trim());\n      if (parsed.content) {\n        bodyContent = parsed.content;\n        // If unwrapped content has frontmatter, strip it (we already have our own)\n        bodyContent = bodyContent.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n      } else break;\n    } catch (e) { break; }\n    unwrapAttempts++;\n  }\n  \n  // Rebuild clean content\n  const cleanContent = fmMatch ? `---\\n${fmMatch[1]}\\n---\\n\\n${bodyContent}` : bodyContent;\n  \n  // Build output object for reuse\n  const output = { filepath, filename: vaultPath.split('/').pop() || '', current_folder: vaultPath.substring(0, vaultPath.lastIndexOf('/')) || '', relative_path: relativePath, frontmatter, content: cleanContent, has_frontmatter: !!fmMatch, context };\n  \n  // Smart skip logic: compare updated vs last_processed timestamps\n  const lastProcessed = frontmatter.last_processed || frontmatter['last-processed'];\n  const lastUpdated = frontmatter.updated || frontmatter.date;\n  \n  if (frontmatter.status === 'processed' && !frontmatter['needs-manual-review']) {\n    // If we have both timestamps, compare them\n    if (lastProcessed && lastUpdated) {\n      const processed = new Date(lastProcessed);\n      const updated = new Date(lastUpdated);\n      if (processed >= updated) {\n        return { json: { ...output, skip: true, skip_reason: 'unchanged' } };\n      }\n      // File was modified since last processing - needs reprocessing\n    } else {\n      // No timestamps to compare, skip based on status alone\n      return { json: { ...output, skip: true, skip_reason: 'already_processed' } };\n    }\n  }\n  \n  return { json: output };\n} catch (error) {\n  const inputData = $('Find All MD Files').item.json;\n  const vaultPath = inputData.vaultPath || '';\n  const context = inputData.context || {};\n  const vaultRoot = '/Users/joshdavis/Library/Mobile Documents/iCloud~md~obsidian/Documents/dvsobs1';\n  return { json: { filepath: vaultPath ? `${vaultRoot}/${vaultPath}` : '', filename: vaultPath.split('/').pop() || '', current_folder: '', relative_path: vaultPath, frontmatter: {}, content: '', has_frontmatter: false, error: error.message, context } };\n}"
      },
      "id": "parse-frontmatter",
      "name": "Parse Frontmatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-400, 400]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict" },
          "conditions": [{ "id": "skip-check", "leftValue": "={{ $json.skip }}", "rightValue": true, "operator": { "type": "boolean", "operation": "equals" } }],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "skip-already-processed",
      "name": "Skip Already Processed?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-200, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const data = $json;\n\n// Get context from earlier in the chain\nlet context = data.context || {};\nif (!context.attendees) {\n  try {\n    context = $('Find All MD Files').item.json.context || {};\n  } catch (e) {\n    context = {};\n  }\n}\n\nconst contentPreview = (data.content || '').substring(0, 500);\n\n// Build context sections for the prompt\nconst attendeeContext = context.attendees || 'No attendee context available.';\nconst clientContext = context.clients || 'No client context available.';\nconst partnerContext = context.partners || 'No partner context available.';\nconst routingRules = context.routing_rules || '';\n\n// Include discovered folders for better routing\nconst discoveredPeople = (context.discovered_people || []).join(', ') || 'None discovered';\nconst discoveredPartners = (context.discovered_partners || []).join(', ') || 'None discovered';\nconst discoveredTeams = (context.discovered_teams || []).join(', ') || 'None discovered';\nlet discoveredClients = '';\nif (context.discovered_clients && typeof context.discovered_clients === 'object') {\n  discoveredClients = Object.entries(context.discovered_clients)\n    .map(([loc, clients]) => `${loc}: ${clients.join(', ')}`)\n    .join('\\n') || 'None discovered';\n}\n\nconst prompt = `You are analyzing an Obsidian note. First determine its type, then extract type-specific metadata.\n\nFILE PATH: ${data.relative_path || data.filepath}\nFRONTMATTER: ${JSON.stringify(data.frontmatter, null, 2)}\nCONTENT PREVIEW: ${contentPreview}\n\nFULL CONTENT:\n${data.content || ''}\n\n=== CONTEXT FROM CONFIG ===\n\n${attendeeContext}\n\n${clientContext}\n\n${partnerContext}\n\n=== DISCOVERED VAULT STRUCTURE ===\n\nEXISTING 1:1 FOLDERS (people): ${discoveredPeople}\nEXISTING PARTNER FOLDERS: ${discoveredPartners}\nEXISTING TEAM FOLDERS: ${discoveredTeams}\nEXISTING CLIENT FOLDERS BY LOCATION:\n${discoveredClients}\n\n=== STEP 1: TYPE DETECTION ===\nDetermine the note type:\n- meeting: Discussion between people, attendees, action items\n- technical-note: Code, architecture, infrastructure docs\n- draft: Work-in-progress communication or document\n- research: Analysis, industry intel, citations\n- template: Reusable structure with placeholders\n- meta: System logs, automation, configuration\n- concept: Ideas, brainstorming, early-stage thinking\n\n=== STEP 2: TYPE-SPECIFIC EXTRACTION ===\n\nFor MEETING notes, extract:\n- meeting_type: 1on1|customer|partner|internal|unknown\n- person, client, partner, team, location as applicable\n- attendees, summary, action_items, key_topics\n- correct_folder based on: 1on1→Work/Areas/One on One Meetings/{person}/, customer→Work/Projects/Active Deals/Clients/{location}/{client}/, partner→Work/Projects/Active Deals/Partners/{partner}/, internal→Work/Areas/Expedient Teams/{team}/\n\nFor TECHNICAL-NOTE, extract:\n- category: architecture|code|infrastructure|research\n- technologies, related_projects, summary\n- correct_folder: Work/Knowledge/Technical/{category}/\n\nFor DRAFT, extract:\n- draft_type: communication|document|presentation\n- recipient, purpose, title, summary\n- correct_folder: Work/Drafts/{draft_type}s/\n\nFor RESEARCH, extract:\n- topic, category: technical|business|product, subcategory\n- sources, related_to, summary\n- correct_folder based on category\n\nFor TEMPLATE, extract:\n- template_type: automation|document|prompt\n- use_case, variables, summary\n- correct_folder: Work/Templates/{template_type}s/\n\nFor META, extract:\n- meta_type: log|automation|configuration\n- system, summary\n- correct_folder: Work/Meta/{meta_type}s/\n\nFor CONCEPT, extract:\n- title, maturity: idea|exploration|proposed|validated\n- related_project, stakeholders, summary\n- correct_folder: Work/Projects/{related_project}/Concepts/ or Work/Knowledge/Product/Features/\n\n${routingRules ? '=== CUSTOM ROUTING RULES ===\\n' + routingRules : ''}\n\n=== OUTPUT FORMAT ===\nReturn ONLY valid JSON:\n{\n  \"note_type\": \"meeting|technical-note|draft|research|template|meta|concept\",\n  \"type_confidence\": \"high|medium|low\",\n  \"type_reasoning\": \"brief explanation\",\n  ... type-specific fields ...,\n  \"correct_folder\": \"full path\",\n  \"confidence\": \"high|medium|low\",\n  \"needs_manual_review\": true|false\n}\n\nReturn ONLY the JSON, no markdown, no explanation.`;\n\nreturn { json: { ...data, llm_prompt: prompt, context } };"
      },
      "id": "build-llm-prompt",
      "name": "Build LLM Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [0, 300]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "qwen2.5:14b-instruct",
          "mode": "list",
          "cachedResultName": "qwen2.5:14b-instruct"
        },
        "messages": {
          "values": [{ "content": "={{ $json.llm_prompt }}" }]
        },
        "options": { "temperature": 0.1 }
      },
      "type": "@n8n/n8n-nodes-langchain.ollama",
      "typeVersion": 1,
      "position": [200, 300],
      "id": "llm-analyze-note",
      "name": "LLM Analyze Note",
      "credentials": {
        "ollamaApi": {
          "id": "UrA6yVTCmM5YHOen",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "let originalData = {};\ntry {\n  originalData = $('Build LLM Prompt').item.json;\n} catch (e) {\n  originalData = {};\n}\n\nlet llmOutput = '';\nif ($json.output) llmOutput = $json.output;\nelse if ($json.text) llmOutput = $json.text;\nelse if ($json.content) {\n  if (Array.isArray($json.content)) {\n    const tc = $json.content.find(c => c.type === 'text');\n    if (tc && tc.text) llmOutput = tc.text;\n  } else if (typeof $json.content === 'string') llmOutput = $json.content;\n} else if ($json.message) llmOutput = $json.message.content || $json.message.text || '';\n\nlet cleaned = llmOutput.trim().replace(/^```json\\n?/i, '').replace(/^```\\n?/i, '').replace(/\\n?```$/i, '').trim();\n\nlet analysis = { note_type: 'concept', confidence: 'low', needs_manual_review: true };\ntry {\n  analysis = JSON.parse(cleaned);\n} catch (e) {\n  const match = cleaned.match(/\\{[\\s\\S]*\\}/);\n  if (match) {\n    try { analysis = JSON.parse(match[0]); } catch (e2) {}\n  }\n}\n\nif (!analysis.note_type) analysis.note_type = 'concept';\nif (!analysis.confidence) analysis.confidence = 'low';\nif (analysis.needs_manual_review === undefined) analysis.needs_manual_review = analysis.confidence === 'low';\n\nconst vaultRoot = '/Users/joshdavis/Library/Mobile Documents/iCloud~md~obsidian/Documents/dvsobs1';\nlet currentRelative = originalData.relative_path || '';\nconst targetFolder = (analysis.correct_folder || '').replace(/\\/$/, '');\nconst currentDir = currentRelative ? currentRelative.substring(0, currentRelative.lastIndexOf('/')) : '';\nconst needsMove = targetFolder && currentDir !== targetFolder && !currentRelative.startsWith(targetFolder + '/');\n\nreturn {\n  json: {\n    filepath: originalData.filepath || '',\n    filename: originalData.filename || '',\n    current_folder: originalData.current_folder || '',\n    relative_path: originalData.relative_path || '',\n    frontmatter: originalData.frontmatter || {},\n    content: originalData.content || '',\n    has_frontmatter: originalData.has_frontmatter || false,\n    note_type: analysis.note_type,\n    type_confidence: analysis.type_confidence || 'medium',\n    analysis,\n    needs_update: !analysis.needs_manual_review,\n    needs_move: needsMove\n  }\n};"
      },
      "id": "parse-llm-response",
      "name": "Parse LLM Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [400, 300]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict" },
          "conditions": [
            { "id": "review-1", "leftValue": "={{ $json.analysis && $json.analysis.needs_manual_review }}", "rightValue": true, "operator": { "type": "boolean", "operation": "equals" } },
            { "id": "review-2", "leftValue": "={{ $json.analysis && $json.analysis.confidence }}", "rightValue": "low", "operator": { "type": "string", "operation": "equals" } },
            { "id": "review-3", "leftValue": "={{ $json.type_confidence }}", "rightValue": "low", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "or"
        },
        "options": {}
      },
      "id": "needs-manual-review",
      "name": "Needs Manual Review?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [600, 300]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const data = $json;\nconst fm = data.frontmatter || {};\nconst analysis = data.analysis || {};\nconst noteType = data.note_type || 'concept';\n\nlet updated = { type: noteType, created: fm.created || fm.date || new Date().toISOString().split('T')[0], status: 'processed', last_processed: new Date().toISOString().split('T')[0] };\n\nswitch(noteType) {\n  case 'meeting':\n    updated.date = fm.date || updated.created;\n    updated.meeting_type = analysis.meeting_type || 'unknown';\n    if (analysis.person) updated.person = analysis.person;\n    if (analysis.client) updated.client = analysis.client;\n    if (analysis.location) updated.location = analysis.location;\n    if (analysis.partner) updated.partner = analysis.partner;\n    if (analysis.team) updated.team = analysis.team;\n    if (analysis.attendees) updated.attendees = analysis.attendees;\n    if (analysis.summary) updated.summary = analysis.summary;\n    updated.project = fm.project || 'unclassified';\n    break;\n  case 'technical-note':\n    updated.category = analysis.category || 'research';\n    if (analysis.technologies) updated.technologies = analysis.technologies;\n    if (analysis.summary) updated.summary = analysis.summary;\n    break;\n  case 'draft':\n    updated.draft_type = analysis.draft_type || 'document';\n    if (analysis.title) updated.title = analysis.title;\n    if (analysis.summary) updated.summary = analysis.summary;\n    updated.status = 'draft';\n    break;\n  case 'research':\n    updated.category = analysis.category || 'business';\n    if (analysis.topic) updated.topic = analysis.topic;\n    if (analysis.summary) updated.summary = analysis.summary;\n    break;\n  case 'template':\n    updated.template_type = analysis.template_type || 'document';\n    if (analysis.use_case) updated.use_case = analysis.use_case;\n    break;\n  case 'meta':\n    updated.meta_type = analysis.meta_type || 'log';\n    if (analysis.system) updated.system = analysis.system;\n    break;\n  case 'concept':\n    updated.maturity = analysis.maturity || 'idea';\n    if (analysis.title) updated.title = analysis.title;\n    if (analysis.summary) updated.summary = analysis.summary;\n    break;\n}\n\nlet rawContent = data.content || '';\n// Strip existing frontmatter to get body\nlet body = rawContent.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n// Unwrap JSON wrappers recursively\nlet unwrapAttempts = 0;\nwhile (body.trim().startsWith('{\"content\":') && unwrapAttempts < 5) {\n  try {\n    const parsed = JSON.parse(body.trim());\n    if (parsed.content) {\n      body = parsed.content;\n      body = body.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n    } else break;\n  } catch (e) { break; }\n  unwrapAttempts++;\n}\n\n// Extract tags from #Relevant Additional Tags: line\nlet extractedTags = [];\nconst tagLineMatch = body.match(/^#Relevant Additional Tags:\\s*(.*)$/m);\nif (tagLineMatch) {\n  const tagStr = tagLineMatch[1];\n  extractedTags = tagStr.split(/[,\\s]+/).map(t => t.replace(/^#/, '').trim()).filter(t => t.length > 0);\n}\n\n// Merge with existing tags from frontmatter\nlet existingTags = [];\nif (fm.tags) {\n  if (Array.isArray(fm.tags)) existingTags = fm.tags;\n  else if (typeof fm.tags === 'string') {\n    existingTags = fm.tags.split(/[,\\s]+/).map(t => t.replace(/^#/, '').trim()).filter(t => t.length > 0);\n  }\n}\nconst allTags = [...new Set([...existingTags, ...extractedTags])];\nif (allTags.length > 0) updated.tags = allTags;\n\n// Clean body: remove #Summary: and #Relevant Additional Tags: lines\nbody = body.replace(/^#Summary:\\s*.*$/gm, '').replace(/^#Relevant Additional Tags:\\s*.*$/gm, '').replace(/\\n{3,}/g, '\\n\\n').trim();\n\nconst formatValue = (v) => {\n  if (Array.isArray(v)) return `[${v.join(', ')}]`;\n  if (typeof v === 'string' && (v.includes(':') || v.includes('#'))) return `\"${v}\"`;\n  return v;\n};\n\nconst fmLines = Object.entries(updated).filter(([k, v]) => v !== '' && v != null).map(([k, v]) => `${k}: ${formatValue(v)}`).join('\\n');\nconst newFrontmatter = `---\\n${fmLines}\\n---`;\n\nlet newContent = newFrontmatter + '\\n\\n' + body;\n\nif (noteType === 'meeting' && analysis.action_items && analysis.action_items.length && !newContent.includes('## Action Items')) {\n  newContent += `\\n\\n## Action Items\\n${analysis.action_items.map(i => `- [ ] ${i}`).join('\\n')}`;\n}\n\nreturn { json: { filepath: data.filepath, filename: data.filename, current_folder: data.current_folder, relative_path: data.relative_path, updated_content: newContent, note_type: noteType, analysis, needs_move: data.needs_move || false } };"
      },
      "id": "update-frontmatter",
      "name": "Update Frontmatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [800, 200]
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=http://100.111.39.118:27123/vault/{{ $json.relative_path }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "text/markdown",
        "body": "={{ $json.updated_content }}",
        "options": {}
      },
      "id": "write-updated-content",
      "name": "Write Updated Content",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1000, 200],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Preserve data from Update Frontmatter after HTTP write\nconst originalData = $('Update Frontmatter').item.json;\nconst httpResponse = $json;\n\nreturn {\n  json: {\n    ...originalData,\n    needs_update: true,\n    needs_manual_review: false,\n    write_success: !httpResponse.error,\n    error: httpResponse.error || null\n  }\n};"
      },
      "id": "preserve-update-data",
      "name": "Preserve Update Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1100, 200]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict" },
          "conditions": [{ "id": "move-check", "leftValue": "={{ $json.needs_move }}", "rightValue": true, "operator": { "type": "boolean", "operation": "equals" } }],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "needs-move",
      "name": "Needs Move?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1300, 200]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const data = $json;\nconst vaultRoot = '/Users/joshdavis/Library/Mobile Documents/iCloud~md~obsidian/Documents/dvsobs1';\nlet oldRelativePath = data.relative_path || '';\nif (!oldRelativePath && data.filepath) {\n  oldRelativePath = data.filepath.replace(vaultRoot + '/', '');\n}\nconst newFolder = (data.analysis?.correct_folder || '').replace(/\\/$/, '');\nconst newRelativePath = `${newFolder}/${data.filename}`;\n\nreturn { json: { ...data, old_relative_path: oldRelativePath, new_relative_path: newRelativePath, move_content: data.updated_content || data.content } };"
      },
      "id": "prepare-file-move",
      "name": "Prepare File Move",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1400, 100]
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=http://100.111.39.118:27123/vault/{{ $json.new_relative_path }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "text/markdown",
        "body": "={{ $json.move_content }}",
        "options": {}
      },
      "id": "write-file-new-location",
      "name": "Write File to New Location",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1600, 100],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "method": "DELETE",
        "url": "=http://100.111.39.118:27123/vault/{{ $json.old_relative_path }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {}
      },
      "id": "delete-old-file",
      "name": "Delete Old File",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1800, 100],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const data = $json;\nconst fm = data.frontmatter || {};\nconst noteType = data.note_type || 'concept';\n\nconst updated = { ...fm, type: noteType, created: fm.created || new Date().toISOString().split('T')[0], status: 'needs-manual-review', last_processed: new Date().toISOString().split('T')[0] };\n\nlet rawContent = data.content || '';\n// Strip existing frontmatter to get body\nlet body = rawContent.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n// Unwrap JSON wrappers recursively\nlet unwrapAttempts = 0;\nwhile (body.trim().startsWith('{\"content\":') && unwrapAttempts < 5) {\n  try {\n    const parsed = JSON.parse(body.trim());\n    if (parsed.content) {\n      body = parsed.content;\n      body = body.replace(/^---\\n[\\s\\S]*?\\n---\\n*/, '');\n    } else break;\n  } catch (e) { break; }\n  unwrapAttempts++;\n}\n\n// Extract tags from #Relevant Additional Tags: line\nlet extractedTags = [];\nconst tagLineMatch = body.match(/^#Relevant Additional Tags:\\s*(.*)$/m);\nif (tagLineMatch) {\n  const tagStr = tagLineMatch[1];\n  extractedTags = tagStr.split(/[,\\s]+/).map(t => t.replace(/^#/, '').trim()).filter(t => t.length > 0);\n}\n\n// Merge with existing tags and add needs-manual-review\nlet existingTags = [];\nif (fm.tags) {\n  if (Array.isArray(fm.tags)) existingTags = fm.tags;\n  else if (typeof fm.tags === 'string') {\n    existingTags = fm.tags.split(/[,\\s]+/).map(t => t.replace(/^#/, '').trim()).filter(t => t.length > 0);\n  }\n}\nconst allTags = [...new Set([...existingTags, ...extractedTags, 'needs-manual-review'])];\nupdated.tags = allTags;\n\n// Clean body: remove #Summary: and #Relevant Additional Tags: lines\nbody = body.replace(/^#Summary:\\s*.*$/gm, '').replace(/^#Relevant Additional Tags:\\s*.*$/gm, '').replace(/\\n{3,}/g, '\\n\\n').trim();\n\nconst formatValue = (v) => {\n  if (Array.isArray(v)) return `[${v.join(', ')}]`;\n  if (typeof v === 'string' && (v.includes(':') || v.includes('#'))) return `\"${v}\"`;\n  return v;\n};\n\nconst fmLines = Object.entries(updated).filter(([k, v]) => v !== '' && v != null).map(([k, v]) => `${k}: ${formatValue(v)}`).join('\\n');\nconst newFrontmatter = `---\\n${fmLines}\\n---`;\n\nconst newContent = newFrontmatter + '\\n\\n' + body;\n\nreturn { json: { filepath: data.filepath, filename: data.filename, current_folder: data.current_folder, relative_path: data.relative_path, updated_content: newContent, note_type: noteType, analysis: data.analysis || {} } };"
      },
      "id": "tag-for-manual-review",
      "name": "Tag for Manual Review",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [800, 400]
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=http://100.111.39.118:27123/vault/{{ $json.relative_path }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "text/markdown",
        "body": "={{ $json.updated_content }}",
        "options": {}
      },
      "id": "write-review-tag",
      "name": "Write Review Tag",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1000, 400],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Preserve data from Tag for Manual Review after HTTP write\nconst originalData = $('Tag for Manual Review').item.json;\nconst httpResponse = $json;\n\n// Merge original data with any error from HTTP response\nreturn {\n  json: {\n    ...originalData,\n    needs_update: false,\n    needs_manual_review: true,\n    write_success: !httpResponse.error,\n    error: httpResponse.error || null\n  }\n};"
      },
      "id": "preserve-review-data",
      "name": "Preserve Review Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1200, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Preserve data from Prepare File Move after HTTP delete\nconst originalData = $('Prepare File Move').item.json;\nconst httpResponse = $json;\n\nreturn {\n  json: {\n    ...originalData,\n    needs_update: true,\n    needs_manual_review: false,\n    delete_success: !httpResponse.error,\n    needs_move: true,\n    error: httpResponse.error || null\n  }\n};"
      },
      "id": "preserve-move-data",
      "name": "Preserve Move Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1900, 100]
    },
    {
      "parameters": {},
      "id": "merge-all-results",
      "name": "Merge All Results",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [2000, 300]
    },
    {
      "parameters": {
        "jsCode": "try {\n  let items = [];\n  try { items = $input.all(); } catch (e) { items = $input.item ? [$input.item] : [{ json: $json }]; }\n  if (!Array.isArray(items)) items = items ? [items] : [];\n  \n  const timestamp = new Date().toISOString();\n  const date = timestamp.split('T')[0];\n  const processedItems = items.filter(i => i && i.json && !i.json.skip);\n  \n  const getFilename = (item) => {\n    const j = item.json || {};\n    return j.filename || j.relative_path?.split('/').pop() || 'unknown';\n  };\n  \n  const getPath = (item) => {\n    const j = item.json || {};\n    return j.relative_path || j.filepath || 'unknown';\n  };\n  \n  const formatError = (err) => {\n    if (!err) return '';\n    if (typeof err === 'string') return err;\n    if (err.message) return err.message;\n    return JSON.stringify(err);\n  };\n  \n  const typeBreakdown = { meeting: 0, 'technical-note': 0, draft: 0, research: 0, template: 0, meta: 0, concept: 0 };\n  processedItems.forEach(i => {\n    const noteType = i.json.note_type || 'concept';\n    if (typeBreakdown[noteType] !== undefined) typeBreakdown[noteType]++;\n  });\n  \n  // Use explicit flags from Preserve nodes\n  const updatedFiles = processedItems.filter(i => i.json.needs_update && !i.json.needs_manual_review && !i.json.error);\n  const reviewFiles = processedItems.filter(i => i.json.needs_manual_review || i.json.error);\n  const movedFiles = processedItems.filter(i => i.json.needs_move && !i.json.error);\n  const errorFiles = processedItems.filter(i => i.json.error);\n  \n  const stats = {\n    total: processedItems.length,\n    updated: updatedFiles.length,\n    moved: movedFiles.length,\n    needs_review: reviewFiles.length,\n    errors: errorFiles.length\n  };\n  \n  let log = `# Metis Log - ${timestamp}\\n\\n`;\n  log += `## Summary\\n\\n`;\n  log += `| Metric | Count |\\n|--------|-------|\\n`;\n  log += `| Total Processed | ${stats.total} |\\n`;\n  log += `| Updated Successfully | ${stats.updated} |\\n`;\n  log += `| Files Moved | ${stats.moved} |\\n`;\n  log += `| Flagged for Review | ${stats.needs_review} |\\n`;\n  log += `| Errors | ${stats.errors} |\\n`;\n  \n  log += `\\n## By Type\\n\\n`;\n  log += `| Type | Count |\\n|------|-------|\\n`;\n  Object.entries(typeBreakdown).forEach(([type, count]) => {\n    if (count > 0) log += `| ${type} | ${count} |\\n`;\n  });\n  \n  log += `\\n---\\n\\n## Updated Successfully\\n\\n`;\n  if (updatedFiles.length > 0) {\n    log += `| File | Type | Confidence | Folder |\\n|------|------|------------|--------|\\n`;\n    updatedFiles.forEach(i => {\n      const j = i.json;\n      const conf = j.analysis?.confidence || j.type_confidence || 'unknown';\n      const folder = j.analysis?.correct_folder || j.current_folder || '-';\n      log += `| [[${getFilename(i)}]] | ${j.note_type || 'unknown'} | ${conf} | ${folder} |\\n`;\n    });\n  } else {\n    log += `*None*\\n`;\n  }\n  \n  log += `\\n## Flagged for Manual Review\\n\\n`;\n  if (reviewFiles.length > 0) {\n    log += `| File | Type | Confidence | Reason |\\n|------|------|------------|--------|\\n`;\n    reviewFiles.forEach(i => {\n      const j = i.json;\n      const conf = j.analysis?.confidence || j.type_confidence || 'low';\n      let reason = j.analysis?.type_reasoning || 'Low confidence';\n      if (j.error) reason = `Error: ${formatError(j.error)}`;\n      log += `| [[${getFilename(i)}]] | ${j.note_type || 'unknown'} | ${conf} | ${reason.substring(0, 50)} |\\n`;\n    });\n  } else {\n    log += `*None*\\n`;\n  }\n  \n  log += `\\n## Files Moved\\n\\n`;\n  if (movedFiles.length > 0) {\n    log += `| File | From | To |\\n|------|------|----|\\n`;\n    movedFiles.forEach(i => {\n      const j = i.json;\n      const from = j.current_folder || j.old_relative_path || '-';\n      const to = j.analysis?.correct_folder || j.new_relative_path || '-';\n      log += `| [[${getFilename(i)}]] | ${from} | ${to} |\\n`;\n    });\n  } else {\n    log += `*None*\\n`;\n  }\n  \n  if (errorFiles.length > 0) {\n    log += `\\n## Errors\\n\\n`;\n    log += `| File | Error |\\n|------|-------|\\n`;\n    errorFiles.forEach(i => {\n      const j = i.json;\n      log += `| [[${getFilename(i)}]] | ${formatError(j.error)} |\\n`;\n    });\n  }\n  \n  log += `\\n---\\n*Generated by Metis at ${timestamp}*\\n`;\n  \n  return { json: { log_content: log, log_path: `Work/Meta/Logs/Metis-Log-${date}.md`, stats } };\n} catch (error) {\n  return { json: { log_content: `# Metis Log\\n\\nError: ${error.message}\\n`, log_path: `Work/Meta/Logs/Metis-Log-${new Date().toISOString().split('T')[0]}.md`, stats: { total: 0, errors: 1 } } };\n}"
      },
      "id": "build-summary-log",
      "name": "Build Summary Log",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2200, 300]
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "=http://100.111.39.118:27123/vault/{{ $json.log_path }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "contentType": "raw",
        "rawContentType": "text/markdown",
        "body": "={{ $json.log_content }}",
        "options": {}
      },
      "id": "write-log-file",
      "name": "Write Log File",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [2400, 300],
      "credentials": {
        "httpBearerAuth": {
          "id": "0e6NCchfeK4TA18n",
          "name": "Obsidian Local REST API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ { success: true, message: 'Metis completed', log_path: $json.log_path, stats: $json.stats } }}",
        "options": {}
      },
      "id": "webhook-response",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2600, 300]
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook Trigger": {
      "main": [[
        { "node": "Read Config Note", "type": "main", "index": 0 },
        { "node": "Scan Vault Structure", "type": "main", "index": 0 }
      ]]
    },
    "Nightly Cron (2am)": {
      "main": [[
        { "node": "Read Config Note", "type": "main", "index": 0 },
        { "node": "Scan Vault Structure", "type": "main", "index": 0 }
      ]]
    },
    "Read Config Note": {
      "main": [[{ "node": "Merge Context Inputs", "type": "main", "index": 0 }]]
    },
    "Scan Vault Structure": {
      "main": [[{ "node": "Merge Context Inputs", "type": "main", "index": 1 }]]
    },
    "Merge Context Inputs": {
      "main": [[{ "node": "Store Context", "type": "main", "index": 0 }]]
    },
    "Store Context": {
      "main": [[{ "node": "Find All MD Files", "type": "main", "index": 0 }]]
    },
    "Find All MD Files": {
      "main": [[{ "node": "Read File Content", "type": "main", "index": 0 }]]
    },
    "Read File Content": {
      "main": [[{ "node": "Parse Frontmatter", "type": "main", "index": 0 }]]
    },
    "Parse Frontmatter": {
      "main": [[{ "node": "Skip Already Processed?", "type": "main", "index": 0 }]]
    },
    "Skip Already Processed?": {
      "main": [
        [{ "node": "Merge All Results", "type": "main", "index": 0 }],
        [{ "node": "Build LLM Prompt", "type": "main", "index": 0 }]
      ]
    },
    "Build LLM Prompt": {
      "main": [[{ "node": "LLM Analyze Note", "type": "main", "index": 0 }]]
    },
    "LLM Analyze Note": {
      "main": [[{ "node": "Parse LLM Response", "type": "main", "index": 0 }]]
    },
    "Parse LLM Response": {
      "main": [[{ "node": "Needs Manual Review?", "type": "main", "index": 0 }]]
    },
    "Needs Manual Review?": {
      "main": [
        [{ "node": "Update Frontmatter", "type": "main", "index": 0 }],
        [{ "node": "Tag for Manual Review", "type": "main", "index": 0 }]
      ]
    },
    "Update Frontmatter": {
      "main": [[{ "node": "Write Updated Content", "type": "main", "index": 0 }]]
    },
    "Write Updated Content": {
      "main": [[{ "node": "Preserve Update Data", "type": "main", "index": 0 }]]
    },
    "Preserve Update Data": {
      "main": [[{ "node": "Needs Move?", "type": "main", "index": 0 }]]
    },
    "Needs Move?": {
      "main": [
        [{ "node": "Prepare File Move", "type": "main", "index": 0 }],
        [{ "node": "Merge All Results", "type": "main", "index": 0 }]
      ]
    },
    "Prepare File Move": {
      "main": [[{ "node": "Write File to New Location", "type": "main", "index": 0 }]]
    },
    "Write File to New Location": {
      "main": [[{ "node": "Delete Old File", "type": "main", "index": 0 }]]
    },
    "Delete Old File": {
      "main": [[{ "node": "Preserve Move Data", "type": "main", "index": 0 }]]
    },
    "Preserve Move Data": {
      "main": [[{ "node": "Merge All Results", "type": "main", "index": 0 }]]
    },
    "Tag for Manual Review": {
      "main": [[{ "node": "Write Review Tag", "type": "main", "index": 0 }]]
    },
    "Write Review Tag": {
      "main": [[{ "node": "Preserve Review Data", "type": "main", "index": 0 }]]
    },
    "Preserve Review Data": {
      "main": [[{ "node": "Merge All Results", "type": "main", "index": 0 }]]
    },
    "Merge All Results": {
      "main": [[{ "node": "Build Summary Log", "type": "main", "index": 0 }]]
    },
    "Build Summary Log": {
      "main": [[{ "node": "Write Log File", "type": "main", "index": 0 }]]
    },
    "Write Log File": {
      "main": [[{ "node": "Webhook Response", "type": "main", "index": 0 }]]
    }
  },
  "active": false,
  "settings": { "executionOrder": "v1" },
  "versionId": "metis-v2-simplified",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "c5e1547f5523d07350ad127eb528b0babf5905357fceb6236c1dac12d13b637a"
  },
  "id": "MetisWorkflow001",
  "tags": []
}
